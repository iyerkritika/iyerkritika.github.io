- project:
  title: Emotion & Attention level detection in PABI robot
  time: Dec '17 - May '18
  details: " This was research done as a continuation of the project done in my deep learning class. I obtained two other datasets; the CAFE data set and the KDEF data set. These had images of higher resolution but less data than the Kaggle data set.  After consideration, we decided to consider their facial features instead of the image as a whole and used the Kaggle dataset, CAFE, and KDEF and retrained the network. We also classified the emotions into three categories. Positive, negative, and neutral. Doing this gave a final accuracy of 85.19%
  <br><br>
  We took inputs from behavioral analysts and used those to train on videos of various children to detect attention level. We used different models to compare the results and validate. These ranged from 80 - 94% accuracy. We used only two classifications of on task and off task.
  <br><br>
  Since this is part of ongoing research, all the data and results are confidential. I cannot show any videos of the children and how the algorithm worked on the children."
  software: "Keras, theano, Skitlearn, tensorflow, Python,Harr face detect, feature exctraction."
  report: DR_report
  # provid:
  # proimage:

- project:
  title: Emotion detection for children with ASD using deep learning
  link: Emotion_tracking_DL
  time: Aug '17 - Dec '18
  details: "Autism Spectrum Disorder(ASD) is a neurological disorder that causes the late development of motor and social skills. PABI(Penguin for Autism Behavioral Intervention) is a robot that helps children with ASD improve their social skills. It is paired with a tablet and gives various audiovisual queues as positive reinforcement for the right answers.
  <br><br>
  This project furthers the assistance of the robot by making it capable of recognizing emotions. Doing this can show how much of the sessions are helping the child and keeping them involved.
  <br><br>
  The FERC Kaggle data set, consisting of 7 emotions (anger, disgust, happy, sad, surprise, fear, and neutral) was used for this project. The dataset had some bad images in it which were removed. It also had an uneven amount of data for each label so, anger and disgust were combined into one as they exhibit a similar negative sentiment. Finally, the data was flipped and augmented to have the same number of samples in each label. It was then put into a pickle file and run on the model. The model consists of various Convolutions, Max-pooling, Flattening, Batch-normalizations, and dropout layers with relu and softmax activation functions.
  <br><br>
  The maximum accuracy reached on these emotions was 57.22%. On seeing the confusion matrix, it was clear that fear was the weak link. After removing fear, the model trained to an accuracy of 68.50%. The highest accuracy recorded on this dataset is 71.2%.
  <br><br>
  The video below shows how the trained model works on live video test data. I tweaked the final layer to show <q>unsure</q> if the confidence was less than 50%."
  software: "Keras, theano, Skitlearn, tensorflow, Anaconda Environment, Python,Harr face detect."
  report: RBE_595_report
  # proimage:
  provid: https://www.youtube.com/embed/Wzzqim4pnSs

# - project:
#   title: Mapping and motion planning on an RC car
#   link: motion_planning_project
#   time: Jan '17 - May '17
#   details: "Motion planning is one of the most important things needed to move a robot. In this project I took 3 motion planning algorithms, A*, RRT* and ARA* and compared them in 3 different Gazebo worlds for completness, optimality, space and time complexity.
#   <br><br>
#   The 3 worlds are ones with no obstacles, one obstacle and a narrow passage. The goals are the same for each algorithm but change for each world. These algorithms were all coded in c++ with gazebo using ROS. The code can be found in the repo motion_planning_project.
#   <br><br>
#   The video below shows how each algorithm faired in each world * EXPLAIN MORE HERE AFTER TOUCH UP OF CODE*"
#   software: C++, gazebo, ROS, Rviz(for visualization)
#   report: motion_planning_report
#   #proimage: dlap
#   #provid: https://www.youtube.com/embed/36LlwygWWXk

- project:
  title: Modular Teleoperation Framework
  time: Jan '17 - May '17
  link: modular_teleop
  details: "Some robots have a client-server setup where the client dictates what to do and, the server performs the task. In surgical robots, teleoperation is a well-used structure. The surgeon works on the client-side controller and, the server follows those motions on the patient. In this project, my team and I aimed at making a modular teleoperation framework that could help incorporate any client device into any server device. We did have issues automating the inverse kinematics so, we kept the server device constant(ABB IRB 120). We can vary the server device by entering the inverse kinematics for any device.
  <br><br>
  In the video shown below, we decided to work with a haptic device as the client to get haptic feedback during surgeries. The haptic feedback is hard to show in the video. In the end, there is a separate segment showing the force applied by the motors against the direction of motion. Actuating the haptic device(geomagic touch) is displayed on Rviz. There is a bumper sensor coded at the end of the ABB arm which sends signals back to the Geomagic touch via ROS. The force was applied to the motors. "
  software: C++, ROS, Gazebo
  report: Modular_Teleoperation_Framework
  #proimage: dlap
  provid: https://www.youtube.com/embed/eJS6qXRqhds

- project:
  title: Fin Analysis and Modeling for a Manta Ray Fish
  time: Feb '17 - Jun '17
  details: "Manta rays are supremely efficient swimmers and can withstand a wide range of temperatures and pressures. To mimic their body movement would mean to be able to do deep-sea navigation for extended periods. It would also help study manta ray behavior for oceanographers and marine biologists.
  <br><br>
  In this project, I modeled a manta ray fin from anatomically correct ratios in Solidworks. Then I analyzed this fin in Comsol. I did deflection analysis, stress analysis, flow analysis with a velocity of 5m/s for water. It helped me understand which parts of the fin endure more stress and need more reinforcement while designing. The video shows the results of this analysis. "
  software: Solidworks, Comsol
  #proimage: dlap
  provid: https://www.youtube.com/embed/xW60XTqEUqI

- project:
  title: Motion Compensation of Davinci during surgery
  time: Oct '16 - Dec '16
  link: motion_comp
  details: "During surgery on organs that move involuntarily, even under anesthesia, the surgeon moves the instruments to compensate for this motion. It means that it is the surgeon's job to synchronize their movements to the patient's. To make their job easier, my team and I worked on a model that would help the surgeon operate as the system takes care of the motion compensation.
  <br><br>
  We achieved this on a simulation of the Davinci PSM and MTM models on gazebo using ROS. The PSM moved in a combined motion of the MTM and the compensated tissue movement. In the simulation, the platform moves in the form of a randomly generated Fourier transform to simulate tissue. We used an Extended Kalman Filter(EKF) to predict the next position of the platform. The video below shows the results of this model."
  software: C++, Gazebo,ROS
  #proimage: dlap
  provid: https://www.youtube.com/embed/WzyvoLGqVeE

- project:
  title: Safe Driving using Model Predictive Control
  time: Jan '17 - May '17
  link: mpc_control
  details: "There is a boom in interest in self driving cars over the past few years. This project focuses on an algorithm that helps the car stay in lane as well as avoid obstacles safely and return to the lane. This was done using fmincon and yalmip libraries in matlab to optimize the path and produce primitives and reference path lines.
  <br><br>
  The video below shows the red line (the car) avoiding the blue dot (the obstacle) and  rejoining to the keeping the blue stars(the reference trajectory primitives)."
  software: Matlab
  report: control_report
  #proimage: dlap
  provid: https://www.youtube.com/embed/ioxudJXcN8g

- project:
  title: Manta Ray fin actuation using Nitnol wires and Pneumatics
  time: Sept '16 - Dec '16
  details: "Manta rays can swim very efficiently due to the way they flap their fins. In this project, my team and I  wanted to try and replicate this motion using smart materials. We designed a manta ray fin mold in Solidworks and then got the mold 3D printed. We filled the manta ray models with silicone ecoflex-30. Some manta rays had Nitinol wires in them during molding that had been pre-trained to fold in one direction, while others had wires put in them after being molded. Another model was made of a mold with chambers for air to go in.
  <br><br>
  We then applied electricity to the nitinol wires to compare how pre-trained wires worked against the wires we pushed in after molding. We also tested the pneumatic manta ray to see how it would compare to the electric actuation. The results are in the video below."
  software: Solidworks, Ultimaker
  report: manta_report
  #proimage: dlap
  provid: https://www.youtube.com/embed/XknByCPCKAo

- project:
  title: Kiosk for Children with ASD
  time: Sept '15 - May '16
  details: "Autism Spectrum disorder(ASD) not only affects children's social skills but motor skills as well. For my Bachelor's thesis, I designed, fabricated, and programmed a kiosk to help children better their motor skills. Various factors have influenced the design. Autistic children can be sensitive to different stimuli like touch or visual cues such as the texture of balls or LED lights.
  <br><br>
  I included different skill exercises like turning, pressing, picking up, placing, throwing, rolling, and depth perception. I integrated sensors like IR, Ultrasound, and limit switches to track progress. DC motors actuate different motions. One PIC board and one Arduino board control these devices. Programming stores and tracks the progress of each child. The image below shows the final setup."
  software: Embedded C, Solidworks
  report: bach_thesis
  proimage: kiosk.jpg
  #provid: https://www.youtube.com/embed/WzyvoLGqVeE
